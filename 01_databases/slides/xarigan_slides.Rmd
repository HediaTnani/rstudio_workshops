---
title: "Working with Databases in R"
author: 'Alex Gold, Solutions Engineer'
date: "2020-02-26<br><font size = 3>*Credit: Edgar Ruiz, James Blair*</font>"
output:
  xaringan::moon_reader:
    nature:
      highlightLines: true
    css: [default, metropolis, metropolis-fonts]
---

```{r setup, echo = FALSE, include = FALSE}
library(DBI)
library(dplyr)
library(dbplyr)
options(knitr.table.format = "html")
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
```


# Schedule
## I. Strategies for Writing Queries
## II. Mechanics of Querying Databases
 - Connecting
 - Writing + Sending Queries
 
## III. Deploying to RStudio Connect w/ Live Connections
---

# First: Get an Instance

* Go to rstd.io/class
  * Workshop ID: `db_workshop`
* Click the link to your instance
* Login to RStudio Server Pro
  * Username: `db_workshop_user`
  * Password: `db_workshop_pass`
  
--
<br><br>
.center[**Zoom Poll:üëçüèª when you're good to go.**]
  
---

# I. 3 Strategies for Efficient Queries

## 1. Sample and Model
## 2. Chunk and Pull
## 3. Push Compute to Data
--
<br><br>

.center[**You don't have to choose just 1! Combine as needed!**]
---

## Strategy 1: Sample and Model

.center[
![Sample and Model](images/sample_and_model.png)
]
--

üòÉ Use favorite R modeling package (`caret/parsnip/rsample`).

üòÉ Really good for iterating/prototyping.

‚òπÔ∏è Requires care for sampling and scaling. 

‚òπÔ∏è Not good for BI tasks.


---

## 2. Chunk and Pull
.center[
![Chunk and Pull](images/chunk_and_pull.png)
]

--
üòÉ Great when discrete chunks exist.

üòÉ Facilitates parallelization.

‚òπÔ∏è Can‚Äôt have interactions between chunks.

‚òπÔ∏è Eventually pull in all data.

---

## 3. Push Compute to Data
.center[
![Sample and Model](images/push_compute.png)
]
--

üòÉ Take advantage of database strengths.

üòÉ Get whole dataset, but move less data.

‚òπÔ∏è Operations might not be permitted in database.

‚òπÔ∏è Maybe your database is slow?

---
class: center
<br><br><br>
## Questions on Strategies?

---

# II. The Mechanics

For all of our recommendations on using databases, as well as how-tos:

.center[[**db.rstudio.com**](https://db.rstudio.com)]

---

## Mechanics: Connecting

.center[
![Sample and Model](images/db_connect_diagram.png)

]
---

### R Packages: ‚òÇÔ∏ès

`DBI`: "front-end" for database connections w/ back-end options
- "`DBI-compliant`": Back-end that implements DBI API (plays nicely with RStudio)


`odbc`: generic DBI-compliant option, works with Open Database Connectivity (ODBC) system 
- We provide [pro drivers](https://rstudio.com/products/drivers/) free of charge for popular databases.
- Microsoft SQL Server, Oracle, PostgreSQL, Amazon Redshift, Amazon Athena, Google BigQuery, Salesforce, Apache Cassandra, Apache Hive, Apache Impala, Teradata, MySQL, IBM Netezza, MongoDB
- Your database provider may provide an ODBC driver (e.g. SAP Hana).

---

### Connecting

**First Choice: DBI-Compliant R Package for your DB**

Combine R Package and Database Driver in 1!

```
DBI::dbConnect(RPostgres::postgres(), ...)
```
Options: `RPostgres`, `RMariaDB`, `RSQLite`, `bigrquery`
--
<br><br>
**Also Great: Driver + `odbc`**

Use `odbc::odbc` w/ system driver on system.
```
DBI::dbConnect(odbc::odbc(), driver = "Postgres", ...)
```
Requires driver `"Postgres"` be configured in `odbcinst.ini`.
---
# Key Takeaways

If you're not using a database-specific package (`RPostgres`, `RMariaDB`, `RSQLite`, `bigrquery`), 
you need **2(!)** things.

**1** An R session with `DBI` + `odbc` packages.

**2** A system `odbc` driver, probably configured by a Linux admin. 
* You get some drivers with RStudio Pro products. 
* Others may be provided by your database provider.


---

## How to Connect from the RStudio IDE

- Connections Pane - can use point-and-click, generates code
- Code - easier, can be used non-interactively (when deployed)

---

## Securing Credentials: Options

#### Use a DSN 
#### Prompt for Password/Keyring
#### Config Package
#### Environment Variables
<br><br><br>

.small[See https://db.rstudio.com/best-practices/managing-credentials/ for more details.]

---

### Using a DSN
```{r}
con <- dbConnect(odbc::odbc(), "Postgres Prod", timeout = 10)
dbListTables(con)
dbDisconnect(con)
```

*Examine `/etc/odbc.ini` and `/etc/odbcinst.ini` to see how this works.*

---

### Prompting for Passwords
username `rstudio_prod`, pwd `prod_user` (weird order of dialogs...)
```{r, eval = FALSE}
# Note, not run for presentation, because will break in Rmd
con <- dbConnect(
  odbc::odbc(),
  Driver = "PostgreSQL",
  Server = "localhost",
  UID    = rstudioapi::askForPassword("Database user"),
  PWD    = rstudioapi::askForPassword("Database password"),
  Port = 5432,
  Database = "postgres"
)
dbDisconnect(con)
```

---

### Config Package
```{r}
cfg <- config::get()
con <- dbConnect(
  odbc::odbc(),
  Driver = cfg$driver,
  Server = cfg$server,
  UID    = cfg$uid,
  PWD    = cfg$pwd,
  Port   = cfg$port,
  Database = cfg$database
)
dbListTables(con)
dbDisconnect(con)
```
*Examine config file in `~/rstudio_workshops/config.yml`*
---


class: inverse

**Exercise**

_Connect to a database and Explore_

1. Click on the `Connections` tab

2. Click on the `New Connection` button

3. Click on one of the connections.

4. Click OK

5. Explore the `retail` schema in the IDE.

6. Click the disconnect button (red x).

7. Re-connect using code generated by `Connections` tab.

---

## Sending Queries

### SQL code chunks (or scripts)
### `dbGetQuery`
### dplyr

---

### SQL Code Chunks 1/2
.pull-left[
Include a SQL code chunk in RMarkdown.
<br><br>
#### Connect via R.
<br><br><br><br><br>
####Send SQL Query

`{sql, connection = con}`
]
.pull-right[
<br><br>
```{r}
con <- DBI::dbConnect(
  odbc::odbc(), 
  "Postgres Prod"
  )
```
<br>

```{sql, connection = con}
/* SQL Chunk */
SELECT * FROM retail.orders LIMIT 1;
```
]
---
### SQL Code Chunks 2/2

Add an `output.var` argument to read into R

`{sql, connection = con, output.var = "dat"}`

If same for all SQL chunks: `knitr::opts_chunk$set(connection = "con")`

```{sql, connection = con, output.var = "dat"}
/* SQL Chunk */
SELECT * FROM retail.orders LIMIT 2;
```

```{r}
# r chunk
dat
```

---

### `dbGetQuery`

Get a list of tables
```{r}
library(DBI)
DBI::dbListTables(con)
```

### Send a query
```{r}
(dat <- DBI::dbGetQuery(con, "SELECT * FROM retail.date LIMIT 4;"))
```

---

## dplyr + Databases = dbplyr

### Connect to a Table
```{r}
cust <- dplyr::tbl(con, dbplyr::in_schema("retail", "customer"))
head(cust, 2)
```
--

#### Question
What is cust? What will I get from `names(cust)`?

**Zoom Poll:**
1. `customer_id, customer_name, customer_phone, etc`
2. Something weird üëΩ
---
# üëΩüëΩüëΩüëΩüëΩüëΩüëΩ

```{r}
names(cust)
```

--



.pull-left[
### Lazy Eval
dplyr doesn't *do* anything for as long as possible. So cust isn't
an actual table, it's a reference to a table in the SQL server.

Let's dig in.
]
.pull-right[
### Show Query
SQL statement that actually runs when we ran `cust` as a command
```{r}
cust %>%
  dplyr::show_query()
```
]

I could keep adding more if I wanted. This allows `dbplyr` to write the most 
efficient SQL possible.
---
### `collect` for an R `data.frame`
.pull-left[
```{r}
q <- cust
head(q, 3)
names(q)
```
]
.pull-right[
```{r}
q <- collect(q)
head(q, 3)
names(q)
```
]

*Hint:* Look at the first two rows of the un-`collect`ed data.
---

```{r}
cust %>%
  filter(customer_lat < -122) %>%
  collect()

cust %>%
    collect() %>%
  filter(customer_lon < -122)

```



---

### Un-Translated Functions
What happens if I put in an R command w/ no SQL equivalent?
```{r}
cust %>%
  transmute(today = Sys.time()) %>%
  show_query()
```
It just sends the command along - "maybe it's a SQL command?"

If I run this, I get an error, because `Sys.time` is not a Postgres function.

---
### Un-Translated Functions: Option 1/2
#### Translate Before Sending

Prefix w/ `!!` (bang-bang)
.pull-left[
```{r}
cust %>%
  mutate(today = !!Sys.Date()) %>%
  select(today) %>%
  head(3) %>%
  show_query()
```
]
.pull-right[
```{r}
cust %>%
  mutate(today = !!Sys.Date()) %>%
  select(today) %>%
  head(3)
```
]
---

#### Use Built In Functions
Use built-in SQL function `now()` for Postgres
.pull-left[
```{r}
q <- cust %>%
  transmute(today = now())

# Note: not an R function
tryCatch(now(), error = function(e) e)
```
]
.pull-right[
```{r}
# But
head(q, 3)

q  %>%
  show_query()
```
]

---
# To The Workbook!

`~/rstudio_workshops/01_databases/workbook.Rmd` has a workbook in it.

Going to go to breakout rooms to work through it.

If you run into problems, message me!

If you need to refer to these slides, the code is in

`~/rstudio_workshops/01_databases/slides/xarigan_slides.Rmd`

---
# Deploying

If you follow best practices, deploying to RStudio Connect should be seamless!

Remember: your content needs to access the database without you.

Shiny may require special attention for performance (see strategies).

--- 
# Save Workshop Materials



---
# Appendix
- These slides were created with `rmarkdown` and `xaringan`. To learn more about the `xaringan` package, check out Alision's slides from her rstudio::conf 2019 workshop https://arm.rbind.io/slides/xaringan.html
